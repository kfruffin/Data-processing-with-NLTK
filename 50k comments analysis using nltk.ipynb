{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charger', 'design', 'car', 'cigarett', 'lighter', 'mine', 'flap', 'obstruct', 'job']\n",
      "chargerdesign\n",
      "chargercar\n",
      "chargercigarett\n",
      "chargerlighter\n",
      "chargermine\n",
      "chargerflap\n",
      "chargerobstruct\n",
      "chargerjob\n",
      "designcar\n",
      "designcigarett\n",
      "designlighter\n",
      "designmine\n",
      "designflap\n",
      "designobstruct\n",
      "designjob\n",
      "carcigarett\n",
      "carlighter\n",
      "carmine\n",
      "carflap\n",
      "carobstruct\n",
      "carjob\n",
      "cigarettlighter\n",
      "cigarettmine\n",
      "cigarettflap\n",
      "cigarettobstruct\n",
      "cigarettjob\n",
      "lightermine\n",
      "lighterflap\n",
      "lighterobstruct\n",
      "lighterjob\n",
      "mineflap\n",
      "mineobstruct\n",
      "minejob\n",
      "flapobstruct\n",
      "flapjob\n",
      "obstructjob\n",
      "Bybye\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "input_file = pandas.read_csv('50K_comments.csv')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "c = 0\n",
    "# for each paragraph at each index\n",
    "\n",
    "bigrams = {}\n",
    "\n",
    "for para in input_file.get_values():\n",
    "    if c==1:\n",
    "        print 'Bybye'\n",
    "        break\n",
    "    try: # -------------------------------outer try catch block------------------------------------\n",
    "        # break the paragraph into sentences\n",
    "        sentences = sent_tokenize((para[1]))\n",
    "        words_list = [] # reset this list for the new para\n",
    "        try: # -------------------------------inner try catch block-------------------------\n",
    "            for sent in sentences:\n",
    "#               print '----------Sentence----------',sent\n",
    "                filtered_words = [w.strip(',?-!@#$%^&*(:;).') for w in sent.split() if w.strip(',?-!@#$%^&*(:;).') \\\n",
    "                                  and (not w in stopwords)]\n",
    "                tagged = nltk.pos_tag(filtered_words)\n",
    "                named_enty = nltk.ne_chunk(tagged)\n",
    "                \n",
    "                for w in named_enty[1::]:\n",
    "                    # stemming w\n",
    "                    s_word = ps.stem_word(w[0])\n",
    "                    # passing on distinct nouns\n",
    "                    if w[1] == 'NN' and (s_worcd Dd not in words_list):\n",
    "                        words_list.append(s_word)\n",
    "                                         \n",
    "                # word for loop ends here\n",
    "\n",
    "            temp = {w:0 for w in words_list}                    \n",
    "            # generate bigrams for all the nouns for all the sent of this para\n",
    "            \n",
    "            print words_list\n",
    "#             print temp\n",
    "            n = len(words_list)\n",
    "            for i in xrange(n):\n",
    "                for j in xrange(n):\n",
    "                    # ye bas soch liya maine kisi tarah\n",
    "                    if (i != j) and (temp[words_list[i]] < (n-1)) and (temp[words_list[j]] < (n-1)):\n",
    "                        temp[words_list[i]] += 1\n",
    "                        temp[words_list[j]] += 1\n",
    "                        bigram_set = words_list[i] + words_list[j]\n",
    "                        print bigram_set\n",
    "\n",
    "            # sentence for loop ends here\n",
    "        except: # ----------------------------inner try block ends here-------------------\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        \n",
    "    except: # -----------------------------outer try block ends here-----------------------------\n",
    "        pass\n",
    "    c+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 0, 4: 0}\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "2 3\n",
      "2 4\n",
      "3 4\n"
     ]
    }
   ],
   "source": [
    "# nltk.help.upenn_tagset\n",
    "# generating bigrams\n",
    "a = [1,2,3,4]\n",
    "\n",
    "temp = {i:0 for i in a}\n",
    "print temp\n",
    "\n",
    "n = len(a)\n",
    "for i in xrange(n):\n",
    "    for j in xrange(n):\n",
    "        if i != j and (temp[i+1] < (n-1)) and (temp[j+1] < (n-1)):\n",
    "            temp[i+1] += 1 \n",
    "            temp[j+1] += 1 \n",
    "            print a[i],a[j]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
