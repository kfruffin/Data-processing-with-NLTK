{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tobacco:] 45\n",
      "x1f629:x1f637 44\n",
      "librablack:x1f637 43\n",
      "librablack:x1f629 43\n",
      "news:tobacco 32\n",
      "deduct:tobacco 31\n",
      "news:http://twitter.com/VedicVision/status/621641292766818306/photo/1 31\n",
      "news:deduct 31\n",
      "news:] 31\n",
      "tobacco:http://twitter.com/VedicVision/status/621641292766818306/photo/1 31\n",
      "deduct:] 30\n",
      "http://twitter.com/VedicVision/status/621641292766818306/photo/1:] 30\n",
      "deduct:http://twitter.com/VedicVision/status/621641292766818306/photo/1 30\n",
      "ask:cigarett 14\n",
      "spain?tapa:snout 13\n",
      "ask:snout 13\n",
      "cigarett:snout 13\n",
      "red_calum:cigarett 13\n",
      "cigarett:] 13\n",
      "cigarett:spain?tapa 13\n",
      "red_calum:ask 13\n",
      "red_calum:spain?tapa 13\n",
      "red_calum:snout 13\n",
      "ask:spain?tapa 13\n",
      "deal:] 10\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "input_file = pandas.read_csv('50K_comments.csv')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "c = 0\n",
    "# for each paragraph at each index\n",
    "\n",
    "bigrams = {}\n",
    "\n",
    "for para in input_file.get_values()[-500:]:\n",
    "    if c==1000:\n",
    "        break\n",
    "    try: # -------------------------------outer try catch block------------------------------------\n",
    "        # break the paragraph into sentences\n",
    "        sentences = sent_tokenize((para[1]))\n",
    "#         print sentences\n",
    "        words_list = [] # reset this list for the new para\n",
    "        try: # -------------------------------inner try catch block-------------------------\n",
    "            for sent in sentences:\n",
    "#                 print '----------Sentence----------',type(sent)\n",
    "                sent = sent.replace(\"'\", \"\")\n",
    "                filtered_words = [w.strip(',?-!@#$><%^&*(:\\\\;).') for w in sent.split() \\\n",
    "                                  if w.strip(',?-!@#><$%^\\\\&*(:;).') and (not w in stopwords)]\n",
    "#                 print filtered_words\n",
    "                tagged = nltk.pos_tag(filtered_words)\n",
    "#                 named_enty = nltk.ne_chunk(tagged)\n",
    "                for w in tagged:\n",
    "#                     stemming w\n",
    "                    s_word = ps.stem_word(w[0])\n",
    "                    # passing on distinct nouns\n",
    "                    if w[1] == 'NN' and (s_word not in words_list):\n",
    "#                         print s_word\n",
    "                        words_list.append(s_word)\n",
    "                # words (for each sentence) for loop ends here\n",
    "#                 print words_list\n",
    "            temp = {w:0 for w in words_list}              \n",
    "            \n",
    "            # sentence for loop ends here\n",
    "            \n",
    "            # generate bigrams for all the nouns for all the sent of this para\n",
    "            n = len(words_list)\n",
    "            for i in xrange(n):\n",
    "                for j in xrange(n):\n",
    "                    if (i != j) and (temp[words_list[i]] < (n-1)) and (temp[words_list[j]] < (n-1)):\n",
    "                        temp[words_list[i]] += 1\n",
    "                        temp[words_list[j]] += 1\n",
    "                        bigram_set = words_list[i] + ':' + words_list[j]\n",
    "#                         print bigram_set\n",
    "                        if bigram_set not in bigrams.keys():\n",
    "                            bigrams[bigram_set] = 1\n",
    "                        else:\n",
    "                            bigrams[bigram_set] += 1\n",
    "\n",
    "        except: # ----------------------------inner try block ends here-------------------\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        \n",
    "    except: # -----------------------------outer try block ends here-----------------------------\n",
    "        pass\n",
    "    c = c + 1\n",
    "\n",
    "from operator import itemgetter\n",
    "for k,v in sorted(bigrams.items(), reverse=True, key=itemgetter(1)):\n",
    "    if v > 8:\n",
    "        print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 0, 3: 0, 4: 0}\n",
      "[50595L\n",
      " 'Looks Like the Ban Regarding #Maari in SL and Malaysia is due to CONTENT looks like [ Cigarette Scenes ]  is the Major Issue']\n",
      "[50596L\n",
      " 'It feels like hell, but I give myself if you could. You settle... :  It feels like hell, but I give myself if you could. You settle down, But I was holding my eyes from blinking. And I almost choked when you offered me a smoke on your  cigarette . ']\n",
      "[50597L\n",
      " 'RT @librablack: Cigarette smoke is so disgusting &#x1f629; &#x1f637; ']\n",
      "[50598L\n",
      " 'RT @sandp_m4: Shocking! #LiarTimesNow reported wrong news about VAT deduction on tobacco in Rajasthan! http://t.co/ikyhxBNPne [ http://twitter.com/VedicVision/status/621641292766818306/photo/1 ]']\n",
      "[50599L\n",
      " 'RT @loridowney3: Beagles are forced to inhale cigarette smoke-hairspray-bleach until they die to record lethal amounts. #BEAGLEFREEDOM http\\xe2\\x80\\xa6']\n",
      "[50600L\n",
      " 'RT @librablack: Cigarette smoke is so disgusting &#x1f629; &#x1f637; ']\n",
      "[50601L\n",
      " 'Cigarette smoke depletes your body of Vitamin C, which is a key Vitamin for keeping skin plump and wrinkle free!']\n",
      "[50602L\n",
      " '@mp3michael yes, govt based on threat of violence, no doubt. but do you remember the scientists the tobacco industry employed? corrupt.']\n",
      "[50603L\n",
      " 'The amazing love for tobacco and cigarette is the easiest way to have this deadly oral cancer. It is important to... http://t.co/qPc9tQLAEC [ http://www.rightinfobase.com/things-to-know-about-oral-cancer/ ]']\n",
      "[50604L\n",
      " '#teamfollowback Philip Morris expands e-cigarette deal with Altria http://t.co/JIs9ClCWUx [ http://www.reuters.com/article/2015/07/16/altria-group-pmi-deal-idUSL5N0ZW4DE20150716?type=companyNews&feedType=RSS&feedName=companyNews ] #sougofollow']\n"
     ]
    }
   ],
   "source": [
    "# nltk.help.upenn_tagset\n",
    "# generating bigrams\n",
    "a = [1,2,3,4]\n",
    "\n",
    "temp = {i:0 for i in a}\n",
    "print temp\n",
    "\n",
    "n = len(a)\n",
    "for i in xrange(n):\n",
    "    for j in xrange(n):\n",
    "        if i != j and (temp[i+1] < (n-1)) and (temp[j+1] < (n-1)):\n",
    "            temp[i+1] += 1 \n",
    "            temp[j+1] += 1 \n",
    "#             print a[i],a[j]\n",
    "\n",
    "\n",
    "for para in list(input_file.get_values())[-10:]:\n",
    "    print para\n",
    "#     break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
